{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05e39ce-fb35-4188-ad1e-7e2657a76719",
   "metadata": {},
   "source": [
    "(nb_aws)=\n",
    "# Weather station observations\n",
    "\n",
    "In this exercise, we will use **pandas**, **xarray**, **MetPy** and **plotly** to analyze weather station data from a csv file. We will perform data cleaning, manipulation, and visualization to gain insights into the data and explore its characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480f1ba-ac62-4746-a594-a80c6d096e15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Learning objectives:</b><br>\n",
    "<ul>\n",
    " <li>Get familiar with weather station data</li>\n",
    " <li>Quality assessment of measurement time series</li>\n",
    " <li>Data resampling</li>\n",
    " <li>Visualisation with interactive plots</li>\n",
    "</ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40533f9-c55f-4839-8388-85228b8b62b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Prerequisites</b><br>\n",
    "<ul>\n",
    "<li>Basic knowledge of Python, Jupyter Notebooks, and data analysis</li>\n",
    "<li>Familiarity with MetPy, Pandas, and Xarray</li>\n",
    "<li>A csv file containing weather station data (can be downloaded <a href=\"https://github.com/sauterto/clim_env_hydro/blob/main/docs/nb/data/FLX_CH-Dav_missing.csv\" download>here</a>)</li>\n",
    "</ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354f0af-670f-4aa1-ae07-69419d279174",
   "metadata": {},
   "source": [
    "## Load weather station data\n",
    "\n",
    "In this example, the code reads in the 30-min weather stations data from a CSV file using the '**read_csv()**' method from pandas, with the parse_dates and index_col parameters set to True and 0, respectively. This ensures that the first column of the CSV file (the timestamps) is used as the index of the DataFrame, and that the timestamps are converted to datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8fbcc-9f5b-4fca-a2f8-7f7201ee5ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/sauterto/clim_env_hydro/main/docs/nb/data/FLX_CH-Dav_missing.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "# The file contains:\n",
    "# Air temperature       :: t2m\n",
    "# Relative humdity      :: RH\n",
    "# Precipitation         :: precip\n",
    "# Wind speed            :: WS\n",
    "# Wind direction        :: WD\n",
    "# Net radiation         :: NETRAD\n",
    "# Incoming shortwave    :: SW_IN\n",
    "# Outgoing shortwave    :: SW_OUT\n",
    "# Incoming longwave     :: LW_IN\n",
    "# Outgoing longwave     :: LW_OUT\n",
    "# Sensible heat flux    :: H\n",
    "# Latent heat flux      :: LE\n",
    "# Ground heat flux      :: QG\n",
    "# Surface temperature   :: TS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f1f0d-13b9-479d-8d2e-245b5ae8e158",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br>\n",
    "Which other file formats can be read in with pandas?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e26e9-20b5-4405-91d6-020aff047d0d",
   "metadata": {},
   "source": [
    "## Replace missing data\n",
    "\n",
    "Next, we want to view the data to ensure it has been loaded correctly. We use the head() method from Pandas to display the first five rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11930fb3-6d6d-44ac-bc94-7d1fb87df79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed0697-ef25-4ffc-8fd8-00de29e6e4a6",
   "metadata": {},
   "source": [
    "The DataFrame has missing values with the dummy value -9999. We then use the replace method to replace all occurrences of -9999 with NaN (Not a Number), using the NumPy np.nan constant. Finally, we print the updated DataFrame. The inplace=True argument ensures that the original DataFrame is modified, rather than a copy being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce94b2b-32b5-4758-801e-80eb4c09772f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace -9999 with NaN\n",
    "df.replace(-9999, np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27191050-72f1-41de-b6f2-98bd5e4cd2e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Hint!</b> Compare the SW_OUT and LW_OUT column with those of the previous table.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a43d4d-ba25-4fb2-babc-c0f82dd0dbd7",
   "metadata": {},
   "source": [
    "To check for missing values in a Pandas DataFrame, you can use the **isna()** or **isnull()** method, which returns a Boolean DataFrame of the same shape indicating which cells contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00a8ba-1194-4345-a1c4-f3325dd15b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "print(df.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50974355-4c96-48d9-8e08-591f34c2403d",
   "metadata": {},
   "source": [
    "You can also use the isna() or isnull() method along with the **sum()** method to count the number of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5dc6a-d419-44ed-a5ea-6d30cc7eb4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count the number of missing values in each column\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e4489-247e-4a68-8ae3-aaa41c9515d9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br> Find out how to delete all rows containing NaNs with pandas. Note: Check the pandas webpage.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f0aa4-d89c-46d4-82ab-b379b3c04e33",
   "metadata": {},
   "source": [
    "We can also check whether whole periods (missing timestamps) are missing, by generating a date range using the '**date_range()**' method from pandas, with the start and end parameters set to the minimum and maximum timestamps in the DataFrame, respectively, and the freq parameter set to the expected frequency of the time series (e.g. '30T' for every 30 minutes).\n",
    "\n",
    "The \"**difference()**' method is then used to compare the date range to the DataFrame index. If there are any missing periods in the time series, then the resulting set will be non-empty, and the code will print 'The time series is not continuous'. Otherwise, the time series is continuous and the code will print 'The time series is continuous'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1800c-51ff-4993-ac74-1e6532434d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing periods\n",
    "if pd.date_range(start=df.index.min(), end=df.index.max(), freq='30T').difference(df.index).empty:\n",
    "    print('The time series is continuous \\n')\n",
    "else:\n",
    "    print('The time series is not continuous \\n')\n",
    "    print(('These dates are missing: \\n {0}').format(pd.date_range(start=df.index.min(), end=df.index.max(), \n",
    "                                                                 freq='30T').difference(df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30e8eb-c343-47b9-bbef-3bf5e2e7dab1",
   "metadata": {},
   "source": [
    "Calculate some statistics and check if ranges are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1278ed1-1d18-40f4-93c2-1b59f8b41fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 95th-Quantile (extremes)\n",
    "df.quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0f749-0ac3-48d1-beba-968010508c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e61320-5bea-43d0-ae6f-3d238e55d177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean values\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd74a7-f359-4fc6-b73a-b0bc2355d8fe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br> Are these values reasonable?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244eb97c-58c1-4b92-8d38-9d40ca895822",
   "metadata": {},
   "source": [
    "## Resample data\n",
    "\n",
    "The '**resample()**' method is then used to resample the data to hourly frequency, with different aggregation methods specified for each column using the '**agg()**' method. The Temperature column is aggregated using the mean() method, the Relative Humidity column is aggregated using the min() method, the Wind Speed column is aggregated using the max() method, the Wind Direction column is aggregated using the last() method, and the Radiation fluxs are aggregated using the mean() method. This effectively aggregates the data to hourly intervals using different aggregation methods for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa2ef4-7f61-469f-8b1d-3933f83f86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to hourly frequency with different aggregation methods for each column\n",
    "resampled_hourly = df.resample('1H').agg({'t2m': 'mean', 'RH': 'min',\n",
    "                                  'WS': 'max', 'WD': 'last', 'NETRAD': 'mean',\n",
    "                                 'precip':'sum', 'SW_IN':\"mean\", 'SW_OUT':\"mean\",\n",
    "                                 'LW_IN':\"mean\", 'LW_OUT':\"mean\", \"H\":\"mean\", 'LE':\"mean\",\n",
    "                                  'QG':\"mean\", 'TS':\"mean\"})\n",
    "\n",
    "# Find dates with missing data\n",
    "missing_dates = resampled_hourly['t2m'][resampled_hourly['t2m'].isnull()].index\n",
    "print(\"Dates with missing data:\\n\",resampled_hourly.loc[missing_dates])\n",
    "\n",
    "# Check if the time series is continuous (having missing dates)\n",
    "if pd.date_range(start=df.index.min(), end=df.index.max(), freq='H').difference(resampled_hourly.index).empty:\n",
    "    print('The time series is continuous \\n')\n",
    "else:\n",
    "    print('The time series is not continuous \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a95457-98c5-4ccb-96b7-e0d5b50d3213",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br> How do you modify the code to get annual means? Note: See the information on the Pandas page about the resample method, and check <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases\">here</a> for a list of frequency aliases.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d56f60-2bd6-4f88-ad81-b918e0cf951b",
   "metadata": {},
   "source": [
    "If there are long periods without data, the resampling process will still produce hourly intervals with NaNs in place of missing values. The length of the gaps between valid data points will be reflected in the number of consecutive NaN values in the resampled DataFrame.\n",
    "\n",
    "You can also simply determine the minimum number of elements that must be included in the resampling. To resample a DataFrame and return NaN values for columns that do not have sufficient number of elements in the resampling set, you can use the '**resample()**' method in combination with''**agg()**' method and a custom aggregation function that checks for the number of elements in each column and returns NaN if the count is less than a specific threshold. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeeb5b7-5572-45ac-ad32-f36f55685494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resample dataframe with different aggregation for each column and return NaN for \n",
    "# columns with insufficient elements\n",
    "threshold =  23 # minimum number of elements required in resampling set\n",
    "resampled_thres = resampled_hourly.resample('1M').agg({'t2m': lambda x: x.dropna().mean() if x.isna().sum() < threshold else np.nan,\n",
    "                                    'RH': lambda x: x.dropna().mean() if x.isna().sum() < threshold else np.nan})\n",
    "\n",
    "# Find dates with missing data\n",
    "missing_dates = resampled_thres['t2m'][resampled_thres['t2m'].isnull()].index\n",
    "print(\"Dates with missing data:\\n\",resampled_thres.loc[missing_dates])\n",
    "\n",
    "# Check if the time series is continuous\n",
    "if pd.date_range(start=df.index.min(), end=df.index.max(), freq='H').difference(resampled_hourly.index).empty:\n",
    "    print('The time series is continuous \\n')\n",
    "else:\n",
    "    print('The time series is not continuous \\n')\n",
    "    \n",
    "# Plot the temperature time series\n",
    "resampled_thres['t2m'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da37f1c-d451-4613-a96e-a29f17d80384",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Tip!</b> Change the threshold and watch how the time series changes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7561c0a-4a76-4656-9dd9-89969759a168",
   "metadata": {},
   "source": [
    "Here is another example. We can calculate the seasonal mean by resampling the data using the resample() method, and taking the mean of each season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38110c-b6b8-417f-a9d4-942461b9d73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample to the seasonal mean starting from December\n",
    "seasonal_mean = df.resample('QS-DEC').agg({'t2m': 'mean', 'RH': 'min',\n",
    "                                  'WS': 'max', 'WD': 'last', 'NETRAD': 'mean',\n",
    "                                 'precip':'sum', 'SW_IN':\"mean\", 'SW_OUT':\"mean\",\n",
    "                                 'LW_IN':\"mean\", 'LW_OUT':\"mean\", \"H\":\"mean\", 'LE':\"mean\",\n",
    "                                  'QG':\"mean\", 'TS':\"mean\"})\n",
    "\n",
    "# Find out which year had the hottest season\n",
    "hottest_season_year = seasonal_mean['t2m'].idxmax().year\n",
    "\n",
    "# Print the hottest year\n",
    "print(('The hottest year was in {0}').format(hottest_season_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976bc8f-ff60-4dae-a5e9-0b08bb508379",
   "metadata": {},
   "source": [
    "To find the hottest seasons (indices) above a certain quantile using pandas, you can use the quantile() method to calculate the value of the quantile, and then use boolean indexing to filter the DataFrame based on the values above that quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8c38e-bc54-4055-89fc-26cc6639fae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the 95th percentile\n",
    "quantile_95 = seasonal_mean['t2m'].quantile(0.95)\n",
    "\n",
    "# Filter the DataFrame based on values above the 95th percentile\n",
    "indices_above_quantile = seasonal_mean[seasonal_mean['t2m'] > quantile_95].index\n",
    "\n",
    "# Print the hottest years above the 95% quantile\n",
    "print('The hottest years were in: \\b')\n",
    "print(pd.Series(indices_above_quantile.format()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe4f0d-e27b-4bb1-a528-f9d98ccdee9f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br> How do you modify the code to get annual means? Note: See the information on the Pandas page about the resample method, and check <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases\">here</a> for a list of frequency aliases. Try to identify the coldest year.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d73d6c-9e8a-4a1e-b571-0df472cbf961",
   "metadata": {},
   "source": [
    "## Visualize temperature and relative humdity\n",
    "\n",
    "Finally, we can visualize the data to identify patterns and trends in the weather. We use the '**plotly**' library to create interactive plots. In this code, we use '**make_subplots()**'\n",
    " to create two panels in a single figure, with a shared x-axis. We then added the temperature and precipitation data as dashed lines in their respective panels using '**go.Scatter()**'\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99836026-a1ac-4ea4-8d14-ed53fc191e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the plotly library\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Creating the plot with two rows and one column. The plots share the same x-axis so that only labels \n",
    "# for the lower plots are shown\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "# Adding the temperature data as a dashed line in the top panel\n",
    "fig.add_trace(go.Scatter(x=resampled_thres.index, y=resampled_thres['t2m'], line=dict(color='royalblue', dash='solid'), name='Temperature (°C)'),\n",
    "                         row=1, col=1)\n",
    "\n",
    "# Adding the precipitation data as a dashed line in the bottom panel\n",
    "fig.add_trace(go.Scatter(x=resampled_thres.index, y=resampled_thres['RH'], line=dict(color='green', dash='solid'), name='Precipitation (mm)'),\n",
    "                         row=2, col=1)\n",
    "\n",
    "# Adjusting the layout\n",
    "fig.update_layout(title='Temperature and Precipitation', plot_bgcolor='white', width=800, height=600,\n",
    "                  yaxis=dict(title='Temperature (°C)', showgrid=True, gridcolor='lightgray', gridwidth=1),\n",
    "                  yaxis2=dict(title='Precipitation (mm)', showgrid=True, gridcolor='lightgray', gridwidth=1),\n",
    "                  xaxis=dict(title='', tickformat='%d.%m.%Y', showgrid=True, gridcolor='lightgray', gridwidth=1),\n",
    "                  xaxis2=dict(title='Date', tickformat='%d.%m.%Y', showgrid=True, gridcolor='lightgray', gridwidth=1))\n",
    "\n",
    "\n",
    "# Adjusting the axes\n",
    "fig.update_xaxes(nticks=10, row=1, col=1)\n",
    "fig.update_yaxes(nticks=10, row=1, col=1)\n",
    "fig.update_xaxes(nticks=10, row=2, col=1)\n",
    "fig.update_yaxes(nticks=10, row=2, col=1)\n",
    "\n",
    "# Showing the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3a946-a688-4ab3-bdd1-0a6005449320",
   "metadata": {},
   "source": [
    "## Visualize precipitation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b09c82-b855-4c96-98d1-c50dc93a6003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Resample the data to hourly frequency with different aggregation methods for each column\n",
    "resampled_monthly = df.resample('1M').agg({'t2m': 'mean', 'RH': 'min',\n",
    "                                  'WS': 'max', 'WD': 'last', 'NETRAD': 'mean',\n",
    "                                 'precip':'sum', 'SW_IN':\"mean\", 'SW_OUT':\"mean\",\n",
    "                                 'LW_IN':\"mean\", 'LW_OUT':\"mean\", \"H\":\"mean\", 'LE':\"mean\",\n",
    "                                  'QG':\"mean\", 'TS':\"mean\"})\n",
    "\n",
    "# Create a bar plot with Plotly Express\n",
    "fig = px.bar(resampled_monthly, x=resampled_monthly.index, y='precip', color='precip', title='Monthly Precipitation')\n",
    "\n",
    "# Add axis labels and title\n",
    "fig.update_layout(xaxis_title='Month', yaxis_title='Precipitation (mm)', title_x=0.5,\n",
    "                  plot_bgcolor='white', width=800, height=400,)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9c3fc-05e3-49dd-83cc-815cac2695a6",
   "metadata": {},
   "source": [
    "We can also plot the distribution of the monthly precipitation. To do this, we estimate the probability density function with a kernel-density estimate using Gaussian kernels '**gaussian_kde()**'. Kernel density estimation is a way to estimate the probability density function (PDF) of a random variable in a non-parametric way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3a379-28f2-4765-9478-b1f60c6ea9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "\n",
    "# estimate PDF with KDE\n",
    "kde = stats.gaussian_kde(resampled_monthly['precip'])\n",
    "\n",
    "# create a grid of x values for plotting\n",
    "x_vals = np.linspace(0, resampled_monthly['precip'].max(), num=50)\n",
    "\n",
    "# evaluate the PDF at the x values\n",
    "pdf_vals = kde.evaluate(x_vals)\n",
    "\n",
    "# plot the PDF with Plotly\n",
    "fig = px.line(x=x_vals, y=pdf_vals)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80c454-d1d8-48d7-ac38-bf33494d6e2c",
   "metadata": {},
   "source": [
    "## Quality assessment of wind data\n",
    "\n",
    "We remove rows where the wind speed is greater than 100, since that value is likely an outlier. Finally, we remove any rows where the wind direction is not between 0 and 360 degrees, or where the wind direction is not a number using boolean indexing. You can modify this code to perform additional quality assessment checks, depending on your specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca9f74-5d8a-4092-a49c-6c7c5648755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing wind data\n",
    "df.dropna(subset=[\"WS\", \"WD\"], inplace=True)\n",
    "\n",
    "# Remove rows where wind speed is 0\n",
    "df = df[df[\"WS\"] > 0]\n",
    "\n",
    "# Remove rows where wind speed is greater than 100\n",
    "df = df[df[\"WS\"] <= 100]\n",
    "\n",
    "# Remove rows where wind direction is not between 0 and 360 degrees\n",
    "df = df[(df[\"WS\"] >= 0) & (df[\"WS\"] <= 360)]\n",
    "\n",
    "# Remove rows where wind direction is not a number\n",
    "df = df[np.isfinite(df[\"WD\"])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c435c9-bed1-494c-8603-a7bac08599f2",
   "metadata": {},
   "source": [
    "## Create a Windrose\n",
    "\n",
    "In this example, we use the **rosely** library to create a WindRose object to create the windrose chart. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e99e5-5de4-4f15-a054-f713b381e429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import rosely\n",
    "from rosely import WindRose\n",
    "\n",
    "# Create a WindRose object with the resampled hourly data\n",
    "WR = WindRose(resampled_hourly)\n",
    "\n",
    "# create renaming dictionary - the WindRose object requires the variable names ws and wd. We have\n",
    "# to tell the Object the name of our Variables: WS, WD\n",
    "names = {'WS':'ws', 'WD':'wd'}\n",
    "\n",
    "# calculate wind statistics for 8 sectors\n",
    "WR.calc_stats(normed=False, bins=8, variable_names=names)\n",
    "\n",
    "# Generate windrose plot\n",
    "WR.plot(\n",
    "    template='plotly_dark',\n",
    "    colors='haline',\n",
    "    title='Davos, Switzerland',\n",
    "    output_type='show',\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# To view the results of the wind statistics that will be used for the wind rose later, \n",
    "# view the WindRose.wind_df which is created after running WindRose.calc_stats()\n",
    "# Here we all speed and fequencies for the northerly sector\n",
    "WR.wind_df.loc[WR.wind_df.direction=='N']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436034d6-d49f-4038-88da-62dfef5f9847",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br> Plot the statistics for other sectors.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e14bea-d150-43fc-bd46-0ebc34b72aab",
   "metadata": {},
   "source": [
    "## Calculate some indices\n",
    "\n",
    "In this example, we load the weather data from a CSV file and convert the temperature from Fahrenheit to Celsius. We then calculate the wind direction and speed, dew point temperature, heat index, and wind chill using MetPy functions. We also create a daily resampled DataFrame and plot the daily mean temperature and a wind rose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceea56e-3570-45bc-b476-6f7ad6252f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "\n",
    "# Convert the temperature from Fahrenheit to Celsius\n",
    "resampled_monthly['t2m'] = ((resampled_monthly['t2m'] - 32) * 5/9).round(2)\n",
    "\n",
    "# Calculate the wind direction from the U and V components\n",
    "u, v = mpcalc.wind_components(resampled_monthly['WS'].values * units('m/s'), \n",
    "                              resampled_monthly['WD'].values * units.deg)\n",
    "wind_direction = mpcalc.wind_direction(u, v).to('deg').magnitude\n",
    "resampled_monthly['WD'] = wind_direction.round(2)\n",
    "\n",
    "# Calculate the wind speed in knots\n",
    "resampled_monthly['WS kts'] = resampled_monthly['WS'].values * units('m/s').to('knots')\n",
    "\n",
    "# Calculate the relative humidity\n",
    "resampled_monthly['Dew Point'] = mpcalc.dewpoint_from_relative_humidity(resampled_monthly['t2m'].values * units.degC, resampled_monthly['RH'].values * units.percent)\n",
    "\n",
    "# Calculate the heat index\n",
    "resampled_monthly['Heat Index'] = mpcalc.heat_index(resampled_monthly['t2m'].values * units.degC, \n",
    "                                       resampled_monthly['RH'].values * units.percent).to('degC').round(2)\n",
    "\n",
    "# Calculate the wind chill\n",
    "resampled_monthly['Wind Chill'] = mpcalc.windchill(resampled_monthly['t2m'].values * units.degC, \n",
    "                                      resampled_monthly['WS'].values * units('m/s')).to('degC').round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca175ce-a20e-4fee-811f-6abccb77b30e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br>What other indices can we calculate with MetPy?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20448975-405d-446a-9080-d22d63ecf274",
   "metadata": {},
   "source": [
    "Let's create a plot. Here, we plot the difference between the temperature and dew point temperture. This is another measure to identify wet/dry months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c5090-46b4-459b-a7d6-c972fcf0c4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the plot with two rows and one column. The plots share the same x-axis so that only labels \n",
    "# for the lower plots are shown\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "data = resampled_monthly\n",
    "\n",
    "# Adding the temperature data as a dashed line in the top panel\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['t2m']-data['Dew Point'], line=dict(color='royalblue', dash='solid'), name='Temperature (°C)'))\n",
    "\n",
    "# Adjusting the layout\n",
    "fig.update_layout(title='Difference Plot between temperature and dew point', plot_bgcolor='white', width=1200, height=800,\n",
    "                  yaxis=dict(title='Temperature (°C)', showgrid=True, gridcolor='lightgray', gridwidth=1),\n",
    "                  yaxis2=dict(title='Precipitation (mm)', showgrid=True, gridcolor='lightgray', gridwidth=1),\n",
    "                  xaxis=dict(title='', tickformat='%d.%m.%Y', showgrid=True, gridcolor='lightgray', gridwidth=1),\n",
    "                  xaxis2=dict(title='Date', tickformat='%d.%m.%Y', showgrid=True, gridcolor='lightgray', gridwidth=1))\n",
    "\n",
    "\n",
    "# Adjusting the axes\n",
    "fig.update_xaxes(nticks=10, row=1, col=1)\n",
    "fig.update_yaxes(nticks=10, row=1, col=1)\n",
    "fig.update_xaxes(nticks=10, row=2, col=1)\n",
    "fig.update_yaxes(nticks=10, row=2, col=1)\n",
    "\n",
    "# Showing the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f267445-e6e4-4127-8399-24cfcd953d2d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Broaden Knowledge & Comprehension</b></br> What are the driest months?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00067f8-47f1-4bc0-a0a3-f2fec763de7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo",
   "language": "python",
   "name": "meteo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}